#!/bin/bash

set -e

#########################################################
#
# Platform: NCI Gadi HPC
#
# Author: Tracy Chew
# tracy.chew@sydney.edu.au
#
# If you use this script towards a publication, please acknowledge the
# Sydney Informatics Hub (or co-authorship, where appropriate).
#
# Suggested acknowledgement:
# The authors acknowledge the scientific and technical assistance
# <or e.g. bioinformatics assistance of <PERSON>> of Sydney Informatics
# Hub and resources and services from the National Computational
# Infrastructure (NCI), which is supported by the Australian Government
# with access facilitated by the University of Sydney.
#
#########################################################

# Quite variable depending on BAM size
# Future - run each BAM as an independant job
# Could also try order inputs by BAM size (descending)

#PBS -P <project>
#PBS -N htseq-count
#PBS -l walltime=30:00:00,ncpus=240,mem=950GB,wd
#PBS -q normal
#PBS -W umask=022
#PBS -l storage=scratch/<project>
#PBS -o ./Logs/htseq-count.o
#PBS -e ./Logs/htseq-count.e

module load openmpi/4.0.2
module load nci-parallel/1.0.0a
module load python3/3.8.5
export PYTHONPATH=$HOME/.local/lib/python3.8/site-packages

mkdir -p ./Logs

# NCPUS per task
NCPUS=1

SCRIPT=./htseq-count.sh
INPUTS=./Inputs/htseq-count.inputs

#########################################################
# Do not edit below this line
#########################################################

M=$(( PBS_NCI_NCPUS_PER_NODE / NCPUS )) #tasks per node

sed "s|^|${SCRIPT} |" ${INPUTS} > ${PBS_JOBFS}/input-file

mpirun --np $((M * PBS_NCPUS / PBS_NCI_NCPUS_PER_NODE)) \
        --map-by node:PE=${NCPUS} \
        nci-parallel \
        --verbose \
        --input-file ${PBS_JOBFS}/input-file
